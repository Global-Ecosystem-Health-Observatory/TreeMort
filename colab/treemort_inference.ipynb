{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e751a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53b66e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(data_folder='/Users/anisr/Documents/AerialImages', hdf5_file='AerialImageModel_ITD.h5', model='flair_unet', backbone=None, epochs=100, train_batch_size=8, val_batch_size=8, test_batch_size=8, train_crop_size=256, val_crop_size=256, test_crop_size=256, val_size=0.2, test_size=0.1, input_channels=4, output_channels=1, output_dir='../output/flair_unet', model_weights='best', learning_rate=0.0001, threshold=0.5, activation='sigmoid', loss='hybrid', resume=True)\n"
     ]
    }
   ],
   "source": [
    "from treemort.utils.config import setup\n",
    "\n",
    "config_file_path = \"../configs/flair_unet_bs8_cs256.txt\"\n",
    "conf = setup(config_file_path)\n",
    "\n",
    "# Modified Config Variables for Local Execution; comment on HPC\n",
    "conf.data_folder = \"/Users/anisr/Documents/AerialImages\"\n",
    "conf.output_dir = os.path.join(\"..\", conf.output_dir)\n",
    "\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9ec1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import geojson\n",
    "import rasterio\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa4dc9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anisr/Documents/TreeSeg/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading or resuming model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtreemort\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Loading or resuming model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m model, optimizer, criterion, metrics \u001b[38;5;241m=\u001b[39m build_model(\u001b[43mconf\u001b[49m, id2label, device)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Model, optimizer, criterion, and metrics are set up.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conf' is not defined"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"alive\", 1: \"dead\"}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "from treemort.modeling.builder import build_model\n",
    "\n",
    "print(\"[INFO] Loading or resuming model...\")\n",
    "model, optimizer, criterion, metrics = build_model(conf, id2label, device)\n",
    "print(f\"[INFO] Model, optimizer, criterion, and metrics are set up.\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint_path = \"/Users/anisr/Documents/TreeSeg/output/hcfnet/best.weights.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "print(f\"[INFO] Loaded weights from {checkpoint_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16253aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_and_preprocess_image(tiff_file):\n",
    "    with rasterio.open(tiff_file) as src:\n",
    "        image = src.read()\n",
    "\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "\n",
    "        transform = src.transform\n",
    "\n",
    "    image = np.transpose(image, (1, 2, 0))  # From (C, H, W) to (H, W, C)\n",
    "\n",
    "    return image, transform\n",
    "\n",
    "\n",
    "def sliding_window_inference(model, image, window_size, stride, device, batch_size=8):\n",
    "    model.eval()  # Ensure model is in evaluation mode\n",
    "\n",
    "    # Pad the image to handle edge cases\n",
    "    padded_image = pad_image(image, window_size)\n",
    "\n",
    "    h, w = padded_image.shape[:2]\n",
    "    prediction_map = np.zeros((h, w), dtype=np.float32)\n",
    "    count_map = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    # List to hold patches for batching\n",
    "    patches = []\n",
    "\n",
    "    # Initialize progress bar\n",
    "    total_patches = ((h - window_size) // stride + 1) * ((w - window_size) // stride + 1)\n",
    "    with tqdm(total=total_patches, desc=\"Processing patches\") as pbar:\n",
    "        \n",
    "        for y in range(0, h - window_size + 1, stride):\n",
    "            for x in range(0, w - window_size + 1, stride):\n",
    "                image_patch = padded_image[y:y + window_size, x:x + window_size]\n",
    "\n",
    "                # Add the patch to the list\n",
    "                patches.append((y, x, image_patch))\n",
    "\n",
    "                # Process the batch if it reaches the specified size\n",
    "                if len(patches) == batch_size:\n",
    "                    process_batch(model, patches, prediction_map, count_map, device)\n",
    "                    patches = []  # Clear the list for the next batch\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Process any remaining patches in the list\n",
    "        if patches:\n",
    "            process_batch(model, patches, prediction_map, count_map, device)\n",
    "\n",
    "    # Normalize prediction map by count map\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        prediction_map /= count_map\n",
    "        prediction_map[count_map == 0] = 0  # Handle divisions by zero\n",
    "\n",
    "    # Crop prediction_map to the original image size\n",
    "    if isinstance(image, tuple):\n",
    "        image = image[0]\n",
    "\n",
    "    prediction_map = prediction_map[:image.shape[0], :image.shape[1]]\n",
    "\n",
    "    return prediction_map\n",
    "\n",
    "def process_batch(model, patches, prediction_map, count_map, device):\n",
    "    # Convert patches to tensors\n",
    "    batch_patches = [torch.from_numpy(patch[2]).permute(2, 0, 1).unsqueeze(0).float().to(device) for patch in patches]\n",
    "    batch_patches_tensor = torch.cat(batch_patches, dim=0)  # Create batch tensor\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_patches_tensor)\n",
    "\n",
    "    # Process each patch in the batch\n",
    "    for (y, x, _), output in zip(patches, outputs):\n",
    "        prediction = output.squeeze(0).squeeze(0).cpu().numpy()\n",
    "        prediction_map[y:y + batch_patches_tensor.shape[2], x:x + batch_patches_tensor.shape[3]] += prediction\n",
    "        count_map[y:y + batch_patches_tensor.shape[2], x:x + batch_patches_tensor.shape[3]] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "'''\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Define process_patch at the top level\n",
    "def process_patch(model, image_patch, device):\n",
    "    image_patch_tensor = torch.from_numpy(image_patch).permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image_patch_tensor)\n",
    "    prediction = output.squeeze(0).squeeze(0).cpu().numpy()\n",
    "    return prediction\n",
    "\n",
    "def sliding_window_inference(model, image, window_size, stride, device):\n",
    "    model.eval()\n",
    "    padded_image = pad_image(image, window_size)\n",
    "\n",
    "    h, w = padded_image.shape[:2]\n",
    "    prediction_map = np.zeros((h, w), dtype=np.float32)\n",
    "    count_map = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    patches = [(padded_image[y : y + window_size, x : x + window_size], device)\n",
    "               for y in range(0, h - window_size + 1, stride)\n",
    "               for x in range(0, w - window_size + 1, stride)]\n",
    "\n",
    "    # Use multiprocessing Pool\n",
    "    with mp.Pool(mp.cpu_count()) as pool:\n",
    "        results = pool.starmap(process_patch, [(model, p, device) for p in patches])\n",
    "\n",
    "    # Aggregate results back to the prediction map\n",
    "    idx = 0\n",
    "    for y in range(0, h - window_size + 1, stride):\n",
    "        for x in range(0, w - window_size + 1, stride):\n",
    "            prediction = results[idx]\n",
    "            prediction_map[y : y + window_size, x : x + window_size] += prediction\n",
    "            count_map[y : y + window_size, x : x + window_size] += 1\n",
    "            idx += 1\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        prediction_map /= count_map\n",
    "        prediction_map[count_map == 0] = 0\n",
    "\n",
    "    if isinstance(image, tuple):\n",
    "        image = image[0]\n",
    "\n",
    "    prediction_map = prediction_map[:image.shape[0], :image.shape[1]]\n",
    "\n",
    "    return prediction_map\n",
    "\n",
    "'''\n",
    "\n",
    "def pad_image(image, window_size):\n",
    "    if isinstance(image, tuple):\n",
    "        image = image[0]\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    pad_h = max(0, window_size - h)\n",
    "    pad_w = max(0, window_size - w)\n",
    "    \n",
    "    return np.pad(image, ((0, pad_h), (0, pad_w), (0, 0)), mode=\"constant\")\n",
    "\n",
    "\n",
    "def threshold_prediction_map(prediction_map, threshold=0.5):\n",
    "    binary_mask = (prediction_map >= threshold).astype(np.uint8)\n",
    "    return binary_mask\n",
    "\n",
    "\n",
    "def extract_contours(binary_mask):\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def apply_transform(contour, transform):\n",
    "    transformed_contour = np.array([transform * (x, y) for x, y in contour])\n",
    "    return transformed_contour\n",
    "\n",
    "\n",
    "def contours_to_geojson(contours, transform, name=\"M4124C_2017_1\", crs=\"urn:ogc:def:crs:EPSG::3067\"):\n",
    "    features = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        if len(contour) >= 3:  # Ensure valid contour (at least 3 points)\n",
    "            contour = contour.reshape(-1, 2)\n",
    "\n",
    "            contour = apply_transform(contour, transform)\n",
    "\n",
    "            if not np.array_equal(contour[0], contour[-1]):\n",
    "                contour = np.vstack([contour, contour[0]])\n",
    "\n",
    "            polygon = Polygon(contour)\n",
    "            feature = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\n",
    "                    \"id\": None,  # Add any properties you need here\n",
    "                    \"max_value\": None\n",
    "                },\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [contour.tolist()]\n",
    "                }\n",
    "            }\n",
    "            features.append(feature)\n",
    "        else:\n",
    "            print(f\"Skipped contour with {len(contour)} points\")\n",
    "\n",
    "    geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"name\": name,\n",
    "        \"crs\": {\n",
    "            \"type\": \"name\",\n",
    "            \"properties\": {\n",
    "                \"name\": crs\n",
    "            }\n",
    "        },\n",
    "        \"features\": features\n",
    "    }\n",
    "    \n",
    "    return geojson\n",
    "\n",
    "\n",
    "def save_geojson(geojson_data, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        geojson.dump(geojson_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7decc795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting process for image: /Users/anisr/Documents/TreeSeg/demo/files/T4323E_1.tif\n",
      "[INFO] Image loaded and preprocessed. Shape: (5882, 4756, 4), Transform: | 0.25, 0.00, 440000.00|\n",
      "| 0.00,-0.25, 7367234.50|\n",
      "| 0.00, 0.00, 1.00|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing patches: 100%|██████████| 1584/1584 [02:25<00:00, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Prediction map generated with shape: (5882, 4756)\n",
      "[INFO] Binary mask created with threshold: 0.5. Mask shape: (5882, 4756)\n",
      "[INFO] 313 contours extracted from binary mask\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 2 points\n",
      "Skipped contour with 1 points\n",
      "Skipped contour with 2 points\n",
      "[INFO] Contours converted to GeoJSON format\n",
      "[INFO] GeoJSON saved to /Users/anisr/Documents/TreeSeg/demo/files/T4323E_1_pred.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def process_image(image_path, window_size=256, stride=128, threshold=0.5):\n",
    "    print(f\"[INFO] Starting process for image: {image_path}\")\n",
    "    \n",
    "    image, transform = load_and_preprocess_image(image_path)\n",
    "    print(f\"[INFO] Image loaded and preprocessed. Shape: {image.shape}, Transform: {transform}\")\n",
    "    \n",
    "    prediction_map = sliding_window_inference(model, image, window_size, stride, device)\n",
    "    print(f\"[INFO] Prediction map generated with shape: {prediction_map.shape}\")\n",
    "    \n",
    "    binary_mask = threshold_prediction_map(prediction_map, threshold)\n",
    "    print(f\"[INFO] Binary mask created with threshold: {threshold}. Mask shape: {binary_mask.shape}\")\n",
    "    \n",
    "    contours = extract_contours(binary_mask)\n",
    "    print(f\"[INFO] {len(contours)} contours extracted from binary mask\")\n",
    "    \n",
    "    geojson_data = contours_to_geojson(contours, transform)\n",
    "    print(f\"[INFO] Contours converted to GeoJSON format\")\n",
    "    \n",
    "    output_geojson_path = os.path.join(os.path.dirname(image_path), os.path.splitext(os.path.basename(image_path))[0] + \"_pred.geojson\")\n",
    "    save_geojson(geojson_data, output_geojson_path)\n",
    "    print(f\"[INFO] GeoJSON saved to {output_geojson_path}\")\n",
    "\n",
    "\n",
    "image_path = \"/Users/anisr/Documents/TreeSeg/demo/files/M4124C_2017_1.tiff\"\n",
    "image_path = \"/Users/anisr/Documents/TreeSeg/demo/files/T4323E_1.tif\"\n",
    "\n",
    "process_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a34bb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def calculate_iou(true_geojson, pred_geojson):\n",
    "    # Load the GeoJSON files\n",
    "    true_gdf = gpd.GeoDataFrame.from_features(true_geojson[\"features\"])\n",
    "    pred_gdf = gpd.GeoDataFrame.from_features(pred_geojson[\"features\"])\n",
    "\n",
    "    intersection_area = 0.0\n",
    "    union_area = 0.0\n",
    "\n",
    "    for true_polygon in true_gdf.geometry:\n",
    "        for pred_polygon in pred_gdf.geometry:\n",
    "            if true_polygon.intersects(pred_polygon):\n",
    "                intersection = true_polygon.intersection(pred_polygon)\n",
    "                union = true_polygon.union(pred_polygon)\n",
    "                \n",
    "                intersection_area += intersection.area\n",
    "                union_area += union.area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"/Users/anisr/Documents/TreeSeg/demo/files/M4124C_2017_1.geojson\") as f:\n",
    "        true_geojson = json.load(f)\n",
    "    \n",
    "    with open(\"/Users/anisr/Documents/TreeSeg/demo/files/M4124C_2017_1_pred.geojson\") as f:\n",
    "        pred_geojson = json.load(f)\n",
    "    \n",
    "    iou_score = calculate_iou(true_geojson, pred_geojson)\n",
    "    print(f\"IoU Score: {iou_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_iou_from_topo(true_topo, pred_topo, threshold=128):\n",
    "    # Convert topological maps to binary masks\n",
    "    true_binary = (true_topo >= threshold).astype(np.uint8)\n",
    "    pred_binary = (pred_topo >= threshold).astype(np.uint8)\n",
    "\n",
    "    # Calculate intersection and union\n",
    "    intersection = np.logical_and(true_binary, pred_binary).sum()\n",
    "    union = np.logical_or(true_binary, pred_binary).sum()\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = intersection / union if union != 0 else 0.0\n",
    "    return iou\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate segmentation maps (replace contours with actual data)\n",
    "    true_topo = segmap_to_topo(true_image_np, true_contours)\n",
    "    pred_topo = segmap_to_topo(pred_image_np, pred_contours)\n",
    "\n",
    "    # Calculate IoU score\n",
    "    iou_score = calculate_iou_from_topo(true_topo, pred_topo)\n",
    "    print(f\"IoU Score: {iou_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
