{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e751a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from treemort.utils.config import setup\n",
    "\n",
    "config_file_path = \"../configs/sa_unet_bs8_cs256.txt\"\n",
    "conf = setup(config_file_path)\n",
    "\n",
    "# Modified Config Variables for Local Execution; comment on HPC\n",
    "conf.data_folder = \"/Users/anisr/Documents/AerialImages\"\n",
    "conf.output_dir = os.path.join(\"..\", conf.output_dir)\n",
    "\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ec1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import geojson\n",
    "import rasterio\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4dc9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"alive\", 1: \"dead\"}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "from treemort.modeling.builder import build_model\n",
    "\n",
    "print(\"[INFO] Loading or resuming model...\")\n",
    "model, optimizer, criterion, metrics = build_model(conf, id2label, device)\n",
    "print(f\"[INFO] Model, optimizer, criterion, and metrics are set up.\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint_path = f\"/Users/anisr/Documents/TreeSeg/output/{conf.model}/best.weights.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "print(f\"[INFO] Loaded weights from {checkpoint_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16253aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon, shape, mapping\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(tiff_file):\n",
    "    with rasterio.open(tiff_file) as src:\n",
    "        image = src.read()\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        transform = src.transform\n",
    "\n",
    "    image = np.transpose(image, (1, 2, 0))  # From (C, H, W) to (H, W, C)\n",
    "\n",
    "    return image, transform\n",
    "\n",
    "\n",
    "def threshold_prediction_map(prediction_map, threshold=0.5):\n",
    "    binary_mask = (prediction_map >= threshold).astype(np.uint8)\n",
    "    return binary_mask\n",
    "\n",
    "\n",
    "def extract_contours(binary_mask):\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def apply_transform(contour, transform):\n",
    "    transformed_contour = np.array([transform * (x, y) for x, y in contour])\n",
    "    return transformed_contour\n",
    "\n",
    "\n",
    "def contours_to_geojson(contours, transform, name, geojson_path):\n",
    "    with open(geojson_path, 'r') as f:\n",
    "        existing_geojson = json.load(f)\n",
    "\n",
    "    existing_properties = existing_geojson['features'][0]['properties'] if existing_geojson['features'] else {}\n",
    "    existing_crs = existing_geojson.get('crs', None)  # Get CRS if it exists, otherwise None\n",
    "\n",
    "    new_features = []\n",
    "    for contour in contours:\n",
    "        if len(contour) >= 3:  # Ensure valid contour (at least 3 points)\n",
    "            contour = contour.reshape(-1, 2)\n",
    "            contour = apply_transform(contour, transform)\n",
    "\n",
    "            if not np.array_equal(contour[0], contour[-1]):\n",
    "                contour = np.vstack([contour, contour[0]])\n",
    "\n",
    "            polygon = Polygon(contour)\n",
    "            new_feature = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": existing_properties.copy(),  # Use the existing properties\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [contour.tolist()]\n",
    "                }\n",
    "            }\n",
    "            new_features.append(new_feature)\n",
    "        else:\n",
    "            print(f\"Skipped contour with {len(contour)} points\")\n",
    "\n",
    "    new_geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"name\": name,\n",
    "        \"crs\": existing_crs,  # Use the same CRS from the existing GeoJSON\n",
    "        \"features\": new_features\n",
    "    }\n",
    "    \n",
    "    return new_geojson\n",
    "\n",
    "\n",
    "def save_geojson(geojson_data, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        geojson.dump(geojson_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfb104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def sliding_window_inference(model, image, window_size=256, stride=128, device='cuda', batch_size=8, threshold=0.5):\n",
    "    model.eval()\n",
    "\n",
    "    padded_image = pad_image(image, window_size)\n",
    "\n",
    "    h, w = padded_image.shape[:2]\n",
    "    prediction_map = np.zeros((h, w), dtype=np.float32)\n",
    "    confidence_map = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    patches = []\n",
    "    coords = []\n",
    "\n",
    "    for y in range(0, h - window_size + 1, stride):\n",
    "        for x in range(0, w - window_size + 1, stride):\n",
    "            patch = padded_image[y:y + window_size, x:x + window_size]\n",
    "            patches.append(patch)\n",
    "            coords.append((y, x))\n",
    "\n",
    "            if len(patches) == batch_size:\n",
    "                prediction_map, confidence_map = process_batch(patches, coords, prediction_map, confidence_map, model, device, threshold)\n",
    "                patches = []\n",
    "                coords = []\n",
    "\n",
    "    if patches:\n",
    "        prediction_map, confidence_map = process_batch(patches, coords, prediction_map, confidence_map, model, device, threshold)\n",
    "\n",
    "    confidence_map[confidence_map == 0] = 1  # Avoid division by zero\n",
    "    # prediction_map /= confidence_map\n",
    "\n",
    "    prediction_map = prediction_map[:image.shape[0], :image.shape[1]]\n",
    "\n",
    "    return prediction_map\n",
    "\n",
    "def process_batch(patches, coords, prediction_map, confidence_map, model, device, threshold=0.5):\n",
    "    batch_tensor = torch.from_numpy(np.array(patches)).permute(0, 3, 1, 2).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_tensor)\n",
    "        predictions = torch.sigmoid(outputs).squeeze(1).cpu().numpy()\n",
    "\n",
    "    for i, (y, x) in enumerate(coords):\n",
    "        confidence = predictions[i]\n",
    "        mask = confidence > threshold\n",
    "        prediction_map[y:y + confidence.shape[0], x:x + confidence.shape[1]] += confidence\n",
    "        confidence_map[y:y + confidence.shape[0], x:x + confidence.shape[1]] += mask.astype(np.float32)\n",
    "\n",
    "    return prediction_map, confidence_map\n",
    "\n",
    "def pad_image(image, window_size):\n",
    "    h, w = image.shape[:2]\n",
    "    pad_h = (window_size - h % window_size) % window_size\n",
    "    pad_w = (window_size - w % window_size) % window_size\n",
    "    padded_image = np.pad(image, ((0, pad_h), (0, pad_w), (0, 0)), mode='constant', constant_values=0)\n",
    "    return padded_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7decc795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_image(image_path, window_size=256, stride=128, threshold=0.5):\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    geojson_path = os.path.join(os.path.dirname(os.path.dirname(image_path)), \"Geojsons\", image_name + \".geojson\")\n",
    "    predictions_path = os.path.join(os.path.dirname(os.path.dirname(image_path)), \"predictions\", image_name + \".geojson\")\n",
    "\n",
    "    print(f\"[INFO] Starting process for image: {image_path}\")\n",
    "    \n",
    "    image, transform = load_and_preprocess_image(image_path)\n",
    "    print(f\"[INFO] Image loaded and preprocessed. Shape: {image.shape}, Transform: {transform}\")\n",
    "    \n",
    "    prediction_map = sliding_window_inference(model, image, window_size, stride, device)\n",
    "    print(f\"[INFO] Prediction map generated with shape: {prediction_map.shape}\")\n",
    "    \n",
    "    binary_mask = threshold_prediction_map(prediction_map, threshold)\n",
    "    print(f\"[INFO] Binary mask created with threshold: {threshold}. Mask shape: {binary_mask.shape}\")\n",
    "    \n",
    "    contours = extract_contours(binary_mask)\n",
    "    print(f\"[INFO] {len(contours)} contours extracted from binary mask\")\n",
    "    \n",
    "    geojson_data = contours_to_geojson(contours, transform, image_name, geojson_path)\n",
    "    print(f\"[INFO] Contours converted to GeoJSON format\")\n",
    "    \n",
    "    save_geojson(geojson_data, predictions_path)\n",
    "    print(f\"[INFO] GeoJSON saved to {predictions_path}\")\n",
    "\n",
    "\n",
    "image_path = \"/Users/anisr/Documents/AerialImages/4band_25cm/M4424E_4_1.tiff\"\n",
    "\n",
    "process_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 256\n",
    "stride = 128\n",
    "\n",
    "image_path = \"/Users/anisr/Documents/AerialImages/4band_25cm/63223_2.tif\"\n",
    "\n",
    "image, transform = load_and_preprocess_image(image_path)\n",
    "\n",
    "prediction_map = sliding_window_inference(model, image, window_size, stride, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7da1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(torch.tensor(prediction_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d53c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edaeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 256\n",
    "stride = 128\n",
    "\n",
    "filename = \"N4212G_2013_1.tiff\"\n",
    "\n",
    "data_folder = \"/Users/anisr/Documents/AerialImages\"\n",
    "\n",
    "tiff_path = os.path.join(data_folder, \"4band_25cm\", filename)\n",
    "geojson_path = os.path.join(data_folder, \"Geojsons\", os.path.splitext(filename)[0] + \".geojson\")\n",
    "predictions_path = os.path.join(data_folder, \"predictions\", os.path.splitext(filename)[0] + \".geojson\")\n",
    "\n",
    "image, transform = load_and_preprocess_image(image_path)\n",
    "print(f\"[INFO] Image loaded and preprocessed. Shape: {image.shape}, Transform: {transform}\")\n",
    "    \n",
    "prediction_map, count_map = sliding_window_inference(model, image, window_size, stride, device)\n",
    "print(f\"[INFO] Prediction map generated with shape: {prediction_map.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def calculate_iou(true_geojson, pred_geojson):\n",
    "\n",
    "    true_gdf = gpd.GeoDataFrame.from_features(true_geojson[\"features\"])\n",
    "    pred_gdf = gpd.GeoDataFrame.from_features(pred_geojson[\"features\"])\n",
    "\n",
    "    intersection_area = 0.0\n",
    "    union_area = 0.0\n",
    "\n",
    "    for true_polygon in true_gdf.geometry:\n",
    "        for pred_polygon in pred_gdf.geometry:\n",
    "            if true_polygon.intersects(pred_polygon):\n",
    "                intersection = true_polygon.intersection(pred_polygon)\n",
    "                union = true_polygon.union(pred_polygon)\n",
    "                \n",
    "                intersection_area += intersection.area\n",
    "                union_area += union.area\n",
    "\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    filename = \"M4424E_4_1.tiff\"\n",
    "\n",
    "    data_folder = \"/Users/anisr/Documents/AerialImages\"\n",
    "\n",
    "    tiff_path = os.path.join(data_folder, \"4band_25cm\", filename)\n",
    "    geojson_path = os.path.join(data_folder, \"Geojsons\", os.path.splitext(filename)[0] + \".geojson\")\n",
    "    predictions_path = os.path.join(data_folder, \"predictions\", os.path.splitext(filename)[0] + \".geojson\")\n",
    "\n",
    "    with open(geojson_path) as f:\n",
    "        true_geojson = json.load(f)\n",
    "    \n",
    "    with open(predictions_path) as f:\n",
    "        pred_geojson = json.load(f)\n",
    "    \n",
    "    iou_score = calculate_iou(true_geojson, pred_geojson)\n",
    "    print(f\"IoU Score: {iou_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fd5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21660b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    \"P5322A_2017_1.tif\",\n",
    "    \"L5242G_2017_1.tif\",\n",
    "    \"M5221F_2016_1.tiff\",\n",
    "    \"L3343D_2019_1.tif\",\n",
    "    \"M-34-56-B-d-1-2_1.tiff\",\n",
    "    \"L3344B_2019_1.tif\",\n",
    "    \"U5224D_1.tif\",\n",
    "    \"N5442C_2014_1.tiff\",\n",
    "    \"N4212G_2013_1.tiff\",\n",
    "    \"L3211A_1.tif\",\n",
    "    \"V4331B_2018_1.tif\",\n",
    "    \"L3433D_2019_1.tif\",\n",
    "    \"P4341G_1.tif\",\n",
    "    \"M4123D_2015_1.tiff\",\n",
    "    \"M4211G_2023_2.tif\",\n",
    "    \"63223_3.tif\",\n",
    "    \"L4411F_tile_3_band_1multiband_tile_3.tif\",\n",
    "    \"Q4211E_2019_1.tif\",\n",
    "    \"N5132F_1.tif\",\n",
    "    \"63471_4_1.tiff\",\n",
    "    \"P5322F_2_1.tiff\",\n",
    "    \"M-34-105-B-b-3-1_1.tiff\",\n",
    "    \"V4331A_2018_1.tif\",\n",
    "    \"M3422E_2016_1.tiff\",\n",
    "    \"M-34-105-B-b-2-4_1.tiff\",\n",
    "]\n",
    "\n",
    "for image_path in image_paths:\n",
    "    process_image(os.path.join(conf.data_folder, \"4band_25cm\", image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701663e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93268443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(tiff_file):\n",
    "    with rasterio.open(tiff_file) as src:\n",
    "        image = src.read()\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        transform = src.transform\n",
    "\n",
    "    image = np.transpose(image, (1, 2, 0))  # From (C, H, W) to (H, W, C)\n",
    "\n",
    "    return image, transform\n",
    "\n",
    "\n",
    "def sliding_window_inference(model, image, window_size, stride, device, batch_size=8):\n",
    "    model.eval()\n",
    "\n",
    "    padded_image = pad_image(image, window_size)\n",
    "\n",
    "    h, w = padded_image.shape[:2]\n",
    "    prediction_map = np.zeros((h, w), dtype=np.float32)\n",
    "    count_map = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    patches = []\n",
    "\n",
    "    total_patches = ((h - window_size) // stride + 1) * ((w - window_size) // stride + 1)\n",
    "    with tqdm(total=total_patches, desc=\"Processing patches\") as pbar:\n",
    "        \n",
    "        for y in range(0, h - window_size + 1, stride):\n",
    "            for x in range(0, w - window_size + 1, stride):\n",
    "                image_patch = padded_image[y:y + window_size, x:x + window_size]\n",
    "\n",
    "                patches.append((y, x, image_patch))\n",
    "\n",
    "                #if len(patches) == batch_size:\n",
    "                #    process_batch(model, patches, prediction_map, count_map, device)\n",
    "                #    patches = []  # Clear the list for the next batch\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        # if patches:\n",
    "        #    process_batch(model, patches, prediction_map, count_map, device)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        prediction_map /= count_map\n",
    "        prediction_map[count_map == 0] = 0  # Handle divisions by zero\n",
    "\n",
    "    if isinstance(image, tuple):\n",
    "        image = image[0]\n",
    "\n",
    "    prediction_map = prediction_map[:image.shape[0], :image.shape[1]]\n",
    "\n",
    "    return prediction_map, patches\n",
    "\n",
    "image_path = \"/Users/anisr/Documents/TreeSeg/demo/files/M4124C_2017_1.tiff\"\n",
    "image, transform = load_and_preprocess_image(image_path)\n",
    "_, patches = sliding_window_inference(model, image, 256, 128, device, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_patches = [torch.from_numpy(patches[i][2]).permute(2, 0, 1).unsqueeze(0).float().to(device) for i in range(8)]\n",
    "batch_patches_tensor = torch.cat(batch_patches, dim=0)  # Create batch tensor\n",
    "\n",
    "print(batch_patches_tensor.shape)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch_patches_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c52107",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape\n",
    "\n",
    "x = 2\n",
    "y = 1\n",
    "\n",
    "window_size = 256\n",
    "stride = 128\n",
    "\n",
    "y*stride, y*stride + batch_patches_tensor.shape[2], x*stride, x*stride + batch_patches_tensor.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ddf7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "384 - 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86007894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_patches_tensor)\n",
    "\n",
    "    for (y, x, _), output in zip(patches, outputs):\n",
    "        prediction = output.squeeze(0).squeeze(0).cpu().numpy()\n",
    "        prediction_map[y:y + batch_patches_tensor.shape[2], x:x + batch_patches_tensor.shape[3]] += prediction\n",
    "        count_map[y:y + batch_patches_tensor.shape[2], x:x + batch_patches_tensor.shape[3]] += 1\n",
    "\n",
    "\n",
    "\n",
    "process_batch(model, patches, prediction_map, count_map, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471e390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a34bb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428c6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_iou_from_topo(true_topo, pred_topo, threshold=128):\n",
    "    # Convert topological maps to binary masks\n",
    "    true_binary = (true_topo >= threshold).astype(np.uint8)\n",
    "    pred_binary = (pred_topo >= threshold).astype(np.uint8)\n",
    "\n",
    "    # Calculate intersection and union\n",
    "    intersection = np.logical_and(true_binary, pred_binary).sum()\n",
    "    union = np.logical_or(true_binary, pred_binary).sum()\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = intersection / union if union != 0 else 0.0\n",
    "    return iou\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate segmentation maps (replace contours with actual data)\n",
    "    true_topo = segmap_to_topo(true_image_np, true_contours)\n",
    "    pred_topo = segmap_to_topo(pred_image_np, pred_contours)\n",
    "\n",
    "    # Calculate IoU score\n",
    "    iou_score = calculate_iou_from_topo(true_topo, pred_topo)\n",
    "    print(f\"IoU Score: {iou_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
